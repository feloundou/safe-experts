{
    "exp_name":	"cpo_500e_8hz_cost1_rew1_lim25",
    "logger":	{
        "<spinup_utils.EpochLogger object at 0x7f0f9e6723a0>":	{
            "epoch_dict":	{},
            "exp_name":	"cpo_500e_8hz_cost1_rew1_lim25",
            "first_row":	true,
            "log_current_row":	{},
            "log_headers":	[],
            "output_dir":	"/home/tyna/Documents/openai/research-project/data/cpo_500e_8hz_cost1_rew1_lim25/cpo_500e_8hz_cost1_rew1_lim25_s0",
            "output_file":	{
                "<_io.TextIOWrapper name='/home/tyna/Documents/openai/research-project/data/cpo_500e_8hz_cost1_rew1_lim25/cpo_500e_8hz_cost1_rew1_lim25_s0/progress.txt' mode='w' encoding='UTF-8'>":	{
                    "mode":	"w"
                }
            }
        }
    },
    "logger_kwargs":	{
        "exp_name":	"cpo_500e_8hz_cost1_rew1_lim25",
        "output_dir":	"/home/tyna/Documents/openai/research-project/data/cpo_500e_8hz_cost1_rew1_lim25/cpo_500e_8hz_cost1_rew1_lim25_s0"
    },
    "n_epochs":	500,
    "self":	{
        "<__main__.CPO object at 0x7f10492ed8e0>":	{
            "cf_lr":	0.01,
            "cg_damping":	0.001,
            "cg_max_iters":	10,
            "continue_from_file":	false,
            "cost_fun":	{
                "Sequential(\n  (0): Linear(in_features=61, out_features=64, bias=True)\n  (1): Tanh()\n  (2): Linear(in_features=64, out_features=64, bias=True)\n  (3): Tanh()\n  (4): Linear(in_features=64, out_features=1, bias=True)\n)":	{
                    "_backward_hooks":	{},
                    "_buffers":	{},
                    "_forward_hooks":	{},
                    "_forward_pre_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "0":	{
                            "Linear(in_features=61, out_features=64, bias=True)":	{
                                "_backward_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_pre_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 0.0076,  0.0616,  0.0688, -0.0307, -0.0979,  0.1229, -0.0940, -0.1046,\n        -0.1132,  0.0311,  0.0531,  0.0623, -0.0408, -0.0240,  0.0744, -0.0256,\n         0.1103, -0.0452,  0.1158,  0.0199,  0.0688, -0.0684, -0.0655,  0.0103,\n         0.0714, -0.0324, -0.0446, -0.0307,  0.0919,  0.0777,  0.0034,  0.0865,\n        -0.1261,  0.1095,  0.0306, -0.0465, -0.0640, -0.0655,  0.0459, -0.0075,\n         0.1211, -0.1208, -0.0756, -0.0359,  0.0342,  0.0969,  0.0629,  0.0312,\n         0.0079, -0.0242, -0.0307,  0.0134, -0.0327, -0.0425,  0.0717,  0.0889,\n         0.0907,  0.0037,  0.0354, -0.0617, -0.0129, -0.0541, -0.0544, -0.0638],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.0808,  0.1033,  0.0352,  ..., -0.1186, -0.0167, -0.0318],\n        [-0.1168, -0.0138, -0.0483,  ..., -0.0089,  0.0299, -0.0152],\n        [-0.0410, -0.0243,  0.0332,  ...,  0.1200, -0.0578, -0.0579],\n        ...,\n        [-0.0165, -0.0387, -0.0664,  ..., -0.1104, -0.0686,  0.1101],\n        [ 0.0441, -0.0544, -0.0670,  ..., -0.0938, -0.0257,  0.0780],\n        [-0.1187,  0.0543,  0.0647,  ...,  0.0386, -0.0690,  0.0644]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "in_features":	"61",
                                "out_features":	64,
                                "training":	true
                            }
                        },
                        "1":	{
                            "Tanh()":	{
                                "_backward_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_pre_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "training":	true
                            }
                        },
                        "2":	{
                            "Linear(in_features=64, out_features=64, bias=True)":	{
                                "_backward_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_pre_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 0.0799,  0.0110, -0.0474,  0.0380,  0.0928,  0.0614,  0.0971,  0.0888,\n        -0.0034,  0.1099, -0.0689, -0.1233,  0.0927, -0.0287,  0.0439, -0.1235,\n         0.0127, -0.0034, -0.0239,  0.0517, -0.1128, -0.0903, -0.0605,  0.0793,\n         0.0715, -0.0047, -0.0844,  0.0092, -0.1137, -0.0231,  0.0516, -0.0317,\n         0.0279,  0.0044,  0.1175,  0.0368,  0.0735,  0.1016,  0.0519,  0.1164,\n        -0.0013, -0.0068,  0.0221,  0.0613, -0.0861, -0.0458, -0.0337,  0.0521,\n        -0.0359,  0.0268,  0.1015, -0.0648,  0.0088,  0.0184,  0.0844, -0.0371,\n        -0.1041, -0.0687, -0.0177,  0.0595, -0.0480,  0.0001,  0.0873,  0.0492],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 0.0205,  0.0556, -0.0428,  ...,  0.0338,  0.1047,  0.0836],\n        [-0.0808, -0.0087,  0.0487,  ...,  0.0345,  0.1064, -0.0045],\n        [-0.0447, -0.0801, -0.0665,  ...,  0.0749, -0.0600,  0.0608],\n        ...,\n        [ 0.0324, -0.1036, -0.0597,  ..., -0.0646,  0.0669,  0.0524],\n        [-0.1068,  0.1137, -0.0846,  ...,  0.0489, -0.1201, -0.1000],\n        [ 0.1049, -0.0022,  0.0134,  ..., -0.0224,  0.0964,  0.0038]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "in_features":	64,
                                "out_features":	64,
                                "training":	true
                            }
                        },
                        "3":	{
                            "Tanh()":	{
                                "_backward_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_pre_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "training":	true
                            }
                        },
                        "4":	{
                            "Linear(in_features=64, out_features=1, bias=True)":	{
                                "_backward_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_pre_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([0.1051], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.0754, -0.0975,  0.0612,  0.0859,  0.0991,  0.0590, -0.0589, -0.1014,\n          0.0854,  0.0486, -0.0549,  0.0439,  0.0169,  0.1018, -0.0300, -0.0781,\n          0.0815, -0.0176, -0.0453, -0.0338, -0.1199, -0.0800, -0.0805,  0.0947,\n         -0.0882,  0.1084,  0.0834,  0.0400,  0.1192, -0.0668,  0.0727, -0.1025,\n         -0.0232,  0.0606, -0.1204, -0.0248,  0.0305,  0.1192,  0.1111, -0.0656,\n         -0.0544, -0.0228, -0.1129, -0.0479, -0.0220, -0.0432, -0.0272, -0.1189,\n         -0.0820, -0.0570,  0.0153, -0.1193,  0.0570, -0.0054,  0.0327, -0.0552,\n         -0.0499, -0.1150,  0.0470,  0.1037,  0.0939, -0.0799,  0.0654,  0.0982]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "in_features":	64,
                                "out_features":	1,
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "training":	true
                }
            },
            "cost_fun_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    eps: 1e-08\n    lr: 0.01\n    weight_decay: 0\n)":	{
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "eps":	1e-08,
                        "lr":	0.01,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "eps":	1e-08,
                            "lr":	0.01,
                            "params":	[
                                "Parameter containing:\ntensor([[-0.0808,  0.1033,  0.0352,  ..., -0.1186, -0.0167, -0.0318],\n        [-0.1168, -0.0138, -0.0483,  ..., -0.0089,  0.0299, -0.0152],\n        [-0.0410, -0.0243,  0.0332,  ...,  0.1200, -0.0578, -0.0579],\n        ...,\n        [-0.0165, -0.0387, -0.0664,  ..., -0.1104, -0.0686,  0.1101],\n        [ 0.0441, -0.0544, -0.0670,  ..., -0.0938, -0.0257,  0.0780],\n        [-0.1187,  0.0543,  0.0647,  ...,  0.0386, -0.0690,  0.0644]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.0076,  0.0616,  0.0688, -0.0307, -0.0979,  0.1229, -0.0940, -0.1046,\n        -0.1132,  0.0311,  0.0531,  0.0623, -0.0408, -0.0240,  0.0744, -0.0256,\n         0.1103, -0.0452,  0.1158,  0.0199,  0.0688, -0.0684, -0.0655,  0.0103,\n         0.0714, -0.0324, -0.0446, -0.0307,  0.0919,  0.0777,  0.0034,  0.0865,\n        -0.1261,  0.1095,  0.0306, -0.0465, -0.0640, -0.0655,  0.0459, -0.0075,\n         0.1211, -0.1208, -0.0756, -0.0359,  0.0342,  0.0969,  0.0629,  0.0312,\n         0.0079, -0.0242, -0.0307,  0.0134, -0.0327, -0.0425,  0.0717,  0.0889,\n         0.0907,  0.0037,  0.0354, -0.0617, -0.0129, -0.0541, -0.0544, -0.0638],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.0205,  0.0556, -0.0428,  ...,  0.0338,  0.1047,  0.0836],\n        [-0.0808, -0.0087,  0.0487,  ...,  0.0345,  0.1064, -0.0045],\n        [-0.0447, -0.0801, -0.0665,  ...,  0.0749, -0.0600,  0.0608],\n        ...,\n        [ 0.0324, -0.1036, -0.0597,  ..., -0.0646,  0.0669,  0.0524],\n        [-0.1068,  0.1137, -0.0846,  ...,  0.0489, -0.1201, -0.1000],\n        [ 0.1049, -0.0022,  0.0134,  ..., -0.0224,  0.0964,  0.0038]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.0799,  0.0110, -0.0474,  0.0380,  0.0928,  0.0614,  0.0971,  0.0888,\n        -0.0034,  0.1099, -0.0689, -0.1233,  0.0927, -0.0287,  0.0439, -0.1235,\n         0.0127, -0.0034, -0.0239,  0.0517, -0.1128, -0.0903, -0.0605,  0.0793,\n         0.0715, -0.0047, -0.0844,  0.0092, -0.1137, -0.0231,  0.0516, -0.0317,\n         0.0279,  0.0044,  0.1175,  0.0368,  0.0735,  0.1016,  0.0519,  0.1164,\n        -0.0013, -0.0068,  0.0221,  0.0613, -0.0861, -0.0458, -0.0337,  0.0521,\n        -0.0359,  0.0268,  0.1015, -0.0648,  0.0088,  0.0184,  0.0844, -0.0371,\n        -0.1041, -0.0687, -0.0177,  0.0595, -0.0480,  0.0001,  0.0873,  0.0492],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.0754, -0.0975,  0.0612,  0.0859,  0.0991,  0.0590, -0.0589, -0.1014,\n          0.0854,  0.0486, -0.0549,  0.0439,  0.0169,  0.1018, -0.0300, -0.0781,\n          0.0815, -0.0176, -0.0453, -0.0338, -0.1199, -0.0800, -0.0805,  0.0947,\n         -0.0882,  0.1084,  0.0834,  0.0400,  0.1192, -0.0668,  0.0727, -0.1025,\n         -0.0232,  0.0606, -0.1204, -0.0248,  0.0305,  0.1192,  0.1111, -0.0656,\n         -0.0544, -0.0228, -0.1129, -0.0479, -0.0220, -0.0432, -0.0272, -0.1189,\n         -0.0820, -0.0570,  0.0153, -0.1193,  0.0570, -0.0054,  0.0327, -0.0552,\n         -0.0499, -0.1150,  0.0470,  0.1037,  0.0939, -0.0799,  0.0654,  0.0982]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([0.1051], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "cost_gamma":	0.995,
            "cost_l2_reg":	0.001,
            "cost_lim":	10,
            "device":	"cpu",
            "elapsed_time":	"0:00:00",
            "epoch_num":	0,
            "gamma":	0.995,
            "line_search_accept_ratio":	0.1,
            "line_search_coef":	0.9,
            "line_search_max_iter":	10,
            "mean_costs":	[],
            "mean_rewards":	[],
            "model_name":	"cpo-run-500e",
            "mse_loss":	{
                "MSELoss()":	{
                    "_backward_hooks":	{},
                    "_buffers":	{},
                    "_forward_hooks":	{},
                    "_forward_pre_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{},
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "reduction":	"mean",
                    "training":	true
                }
            },
            "optim_max_iter":	25,
            "optim_mode":	"adam",
            "policy":	{
                "Sequential(\n  (0): Linear(in_features=60, out_features=64, bias=True)\n  (1): Tanh()\n  (2): Linear(in_features=64, out_features=64, bias=True)\n  (3): Tanh()\n  (4): Linear(in_features=64, out_features=2, bias=True)\n  (5): DiagGaussianLayer()\n)":	{
                    "_backward_hooks":	{},
                    "_buffers":	{},
                    "_forward_hooks":	{},
                    "_forward_pre_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "0":	{
                            "Linear(in_features=60, out_features=64, bias=True)":	{
                                "_backward_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_pre_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 0.1196,  0.0508,  0.0207,  0.0946,  0.1181, -0.0654, -0.0271,  0.0246,\n         0.1150,  0.0663,  0.0160, -0.1042, -0.1173, -0.1135, -0.0339, -0.0525,\n        -0.0680,  0.1072, -0.0758, -0.1027,  0.0534, -0.0645,  0.1201,  0.0920,\n        -0.0718,  0.1079, -0.0380, -0.1177, -0.0931, -0.1073,  0.0423,  0.0103,\n         0.0352, -0.0817,  0.0944,  0.0413,  0.0060, -0.0426,  0.0738, -0.0191,\n         0.0919, -0.0304,  0.0688,  0.1089,  0.0258, -0.0505, -0.0774,  0.0150,\n         0.1230,  0.1160, -0.0232, -0.0029, -0.0818, -0.0194, -0.1036, -0.0280,\n         0.0388,  0.0275, -0.1044, -0.0005,  0.1158, -0.0984, -0.0427,  0.0504],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.0441, -0.0676,  0.0952,  ...,  0.0118,  0.1051,  0.0619],\n        [-0.1143, -0.0741, -0.0564,  ..., -0.0518,  0.0793,  0.0300],\n        [ 0.0434, -0.0802, -0.0259,  ..., -0.0177,  0.0383, -0.0214],\n        ...,\n        [-0.0207,  0.0402,  0.0639,  ..., -0.0040, -0.0666,  0.0735],\n        [ 0.0706, -0.0653,  0.1264,  ...,  0.0091, -0.0014, -0.0478],\n        [-0.0923,  0.0898,  0.0996,  ...,  0.1135,  0.0055, -0.0832]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "in_features":	"60",
                                "out_features":	64,
                                "training":	true
                            }
                        },
                        "1":	{
                            "Tanh()":	{
                                "_backward_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_pre_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "training":	true
                            }
                        },
                        "2":	{
                            "Linear(in_features=64, out_features=64, bias=True)":	{
                                "_backward_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_pre_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.1221,  0.1000, -0.0498,  0.0963, -0.0613, -0.0733, -0.0378, -0.1203,\n        -0.0111,  0.0539, -0.0287,  0.1242,  0.0755, -0.1177,  0.0503, -0.1064,\n        -0.0221,  0.0814, -0.0284, -0.0191,  0.0341, -0.0201, -0.0896, -0.0682,\n         0.0993, -0.0599,  0.1163, -0.0619,  0.0690,  0.0594, -0.0384,  0.1090,\n        -0.1083, -0.1007, -0.0468,  0.0487, -0.0589,  0.0364,  0.0259,  0.0165,\n         0.0936, -0.0532,  0.0899,  0.0311,  0.0682, -0.0631,  0.0274, -0.0357,\n         0.0311, -0.0556,  0.0557, -0.0175, -0.0412,  0.0407, -0.0945,  0.0473,\n         0.1051, -0.0276,  0.0644,  0.1049,  0.0855,  0.1049,  0.0751,  0.1015],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.0773, -0.0187, -0.0406,  ...,  0.0634, -0.0073,  0.0834],\n        [-0.0852,  0.0525,  0.1008,  ...,  0.0609,  0.0575,  0.0665],\n        [ 0.0607, -0.0955, -0.0766,  ..., -0.1069,  0.0094,  0.0175],\n        ...,\n        [ 0.1017, -0.0425, -0.0987,  ..., -0.0359,  0.0625, -0.0482],\n        [ 0.0148,  0.0296, -0.1054,  ..., -0.0814,  0.0723, -0.0120],\n        [ 0.0500,  0.0574,  0.0312,  ..., -0.1243, -0.0971,  0.1032]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "in_features":	64,
                                "out_features":	64,
                                "training":	true
                            }
                        },
                        "3":	{
                            "Tanh()":	{
                                "_backward_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_pre_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "training":	true
                            }
                        },
                        "4":	{
                            "Linear(in_features=64, out_features=2, bias=True)":	{
                                "_backward_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_pre_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0., 0.], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-9.0593e-03, -5.7714e-03, -1.1629e-02,  7.1402e-03, -8.9560e-04,\n          5.6841e-03,  8.2993e-03,  3.9848e-03,  6.0741e-03, -1.0141e-02,\n         -8.6981e-03, -1.3870e-03,  3.7917e-04, -9.0901e-03,  1.1773e-02,\n         -1.1293e-02, -7.0528e-03, -4.9504e-03, -5.6641e-03,  1.1073e-02,\n         -3.9404e-03,  1.7752e-03,  2.0752e-04,  1.1244e-02,  4.4073e-03,\n          8.4379e-03,  4.6590e-03,  1.0776e-02, -8.5071e-03,  9.6056e-03,\n         -5.7509e-03,  3.0118e-04,  9.7896e-03, -6.3426e-03, -3.7848e-03,\n         -1.2486e-02, -1.7134e-03,  1.1765e-02, -6.2197e-06,  1.1862e-02,\n         -1.0749e-02,  3.9092e-03,  6.6097e-03,  7.3458e-03, -1.0869e-02,\n         -4.9005e-03, -3.7488e-03, -1.2336e-02,  1.0913e-02, -8.2800e-03,\n          1.0733e-02,  1.1024e-02, -7.5854e-03, -2.0036e-04,  6.6050e-03,\n         -1.5678e-03, -7.9474e-03, -3.8612e-03, -8.0464e-03,  1.1005e-02,\n         -9.0046e-03,  5.6642e-03, -2.9189e-03, -9.8957e-03],\n        [-1.2393e-02,  1.1136e-02,  9.3192e-03,  4.5420e-03,  7.3658e-03,\n         -4.9418e-03, -1.1346e-02, -1.1669e-02,  6.8598e-03,  3.1753e-03,\n         -9.6692e-03,  1.0578e-02,  8.8273e-03,  3.4194e-03,  7.7702e-04,\n          9.8738e-03, -1.2021e-02,  5.3850e-03,  1.0483e-02, -2.2270e-04,\n          2.6160e-03,  5.8538e-03, -1.0767e-02,  1.0351e-03,  4.0430e-03,\n          1.4126e-03, -9.4084e-05, -9.2370e-03, -8.4414e-03, -7.2095e-03,\n         -1.1478e-02, -4.4379e-03, -1.1372e-02,  9.1958e-03, -8.4558e-03,\n          1.1123e-02,  2.6800e-03, -1.5648e-03, -1.2272e-02,  2.2025e-03,\n         -6.9456e-03, -2.8344e-03, -7.4369e-03, -1.0147e-02, -7.9106e-03,\n          3.0653e-03,  4.3344e-03, -8.8033e-03,  2.9975e-04, -7.5011e-03,\n          7.2806e-03, -4.2036e-03,  4.3761e-03, -8.6310e-03, -7.2043e-03,\n          3.0224e-03, -1.0924e-02, -7.8474e-04, -3.3958e-03,  7.0356e-05,\n         -2.6126e-03,  7.1260e-04,  1.2410e-02, -2.8833e-03]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "in_features":	64,
                                "out_features":	2,
                                "training":	true
                            }
                        },
                        "5":	{
                            "DiagGaussianLayer()":	{
                                "_backward_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_pre_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "log_std":	"Parameter containing:\ntensor([0., 0.], requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "training":	true
                }
            },
            "print_updates":	true,
            "save_dir":	"trained-models-dir",
            "save_every":	10,
            "session_cum_avg_costs":	0,
            "session_cum_avg_rewards":	0,
            "simulator":	{
                "<torch_cpo_utils.SinglePathSimulator object at 0x7f10492ed8b0>":	{
                    "env":	"[<safety_gym.envs.engine.Engine object at 0x7f10492ed910>\n <safety_gym.envs.engine.Engine object at 0x7f1010427220>\n <safety_gym.envs.engine.Engine object at 0x7f1010427a30>\n <safety_gym.envs.engine.Engine object at 0x7f0fd754e280>\n <safety_gym.envs.engine.Engine object at 0x7f0fd754ea90>]",
                    "max_ep_len":	16,
                    "n_episodes":	5,
                    "n_trajectories":	5,
                    "obs_filter":	null,
                    "policy":	{
                        "Sequential(\n  (0): Linear(in_features=60, out_features=64, bias=True)\n  (1): Tanh()\n  (2): Linear(in_features=64, out_features=64, bias=True)\n  (3): Tanh()\n  (4): Linear(in_features=64, out_features=2, bias=True)\n  (5): DiagGaussianLayer()\n)":	{
                            "_backward_hooks":	{},
                            "_buffers":	{},
                            "_forward_hooks":	{},
                            "_forward_pre_hooks":	{},
                            "_load_state_dict_pre_hooks":	{},
                            "_modules":	{
                                "0":	{
                                    "Linear(in_features=60, out_features=64, bias=True)":	{
                                        "_backward_hooks":	{},
                                        "_buffers":	{},
                                        "_forward_hooks":	{},
                                        "_forward_pre_hooks":	{},
                                        "_load_state_dict_pre_hooks":	{},
                                        "_modules":	{},
                                        "_non_persistent_buffers_set":	"set()",
                                        "_parameters":	{
                                            "bias":	"Parameter containing:\ntensor([ 0.1196,  0.0508,  0.0207,  0.0946,  0.1181, -0.0654, -0.0271,  0.0246,\n         0.1150,  0.0663,  0.0160, -0.1042, -0.1173, -0.1135, -0.0339, -0.0525,\n        -0.0680,  0.1072, -0.0758, -0.1027,  0.0534, -0.0645,  0.1201,  0.0920,\n        -0.0718,  0.1079, -0.0380, -0.1177, -0.0931, -0.1073,  0.0423,  0.0103,\n         0.0352, -0.0817,  0.0944,  0.0413,  0.0060, -0.0426,  0.0738, -0.0191,\n         0.0919, -0.0304,  0.0688,  0.1089,  0.0258, -0.0505, -0.0774,  0.0150,\n         0.1230,  0.1160, -0.0232, -0.0029, -0.0818, -0.0194, -0.1036, -0.0280,\n         0.0388,  0.0275, -0.1044, -0.0005,  0.1158, -0.0984, -0.0427,  0.0504],\n       requires_grad=True)",
                                            "weight":	"Parameter containing:\ntensor([[-0.0441, -0.0676,  0.0952,  ...,  0.0118,  0.1051,  0.0619],\n        [-0.1143, -0.0741, -0.0564,  ..., -0.0518,  0.0793,  0.0300],\n        [ 0.0434, -0.0802, -0.0259,  ..., -0.0177,  0.0383, -0.0214],\n        ...,\n        [-0.0207,  0.0402,  0.0639,  ..., -0.0040, -0.0666,  0.0735],\n        [ 0.0706, -0.0653,  0.1264,  ...,  0.0091, -0.0014, -0.0478],\n        [-0.0923,  0.0898,  0.0996,  ...,  0.1135,  0.0055, -0.0832]],\n       requires_grad=True)"
                                        },
                                        "_state_dict_hooks":	{},
                                        "in_features":	"60",
                                        "out_features":	64,
                                        "training":	true
                                    }
                                },
                                "1":	{
                                    "Tanh()":	{
                                        "_backward_hooks":	{},
                                        "_buffers":	{},
                                        "_forward_hooks":	{},
                                        "_forward_pre_hooks":	{},
                                        "_load_state_dict_pre_hooks":	{},
                                        "_modules":	{},
                                        "_non_persistent_buffers_set":	"set()",
                                        "_parameters":	{},
                                        "_state_dict_hooks":	{},
                                        "training":	true
                                    }
                                },
                                "2":	{
                                    "Linear(in_features=64, out_features=64, bias=True)":	{
                                        "_backward_hooks":	{},
                                        "_buffers":	{},
                                        "_forward_hooks":	{},
                                        "_forward_pre_hooks":	{},
                                        "_load_state_dict_pre_hooks":	{},
                                        "_modules":	{},
                                        "_non_persistent_buffers_set":	"set()",
                                        "_parameters":	{
                                            "bias":	"Parameter containing:\ntensor([-0.1221,  0.1000, -0.0498,  0.0963, -0.0613, -0.0733, -0.0378, -0.1203,\n        -0.0111,  0.0539, -0.0287,  0.1242,  0.0755, -0.1177,  0.0503, -0.1064,\n        -0.0221,  0.0814, -0.0284, -0.0191,  0.0341, -0.0201, -0.0896, -0.0682,\n         0.0993, -0.0599,  0.1163, -0.0619,  0.0690,  0.0594, -0.0384,  0.1090,\n        -0.1083, -0.1007, -0.0468,  0.0487, -0.0589,  0.0364,  0.0259,  0.0165,\n         0.0936, -0.0532,  0.0899,  0.0311,  0.0682, -0.0631,  0.0274, -0.0357,\n         0.0311, -0.0556,  0.0557, -0.0175, -0.0412,  0.0407, -0.0945,  0.0473,\n         0.1051, -0.0276,  0.0644,  0.1049,  0.0855,  0.1049,  0.0751,  0.1015],\n       requires_grad=True)",
                                            "weight":	"Parameter containing:\ntensor([[-0.0773, -0.0187, -0.0406,  ...,  0.0634, -0.0073,  0.0834],\n        [-0.0852,  0.0525,  0.1008,  ...,  0.0609,  0.0575,  0.0665],\n        [ 0.0607, -0.0955, -0.0766,  ..., -0.1069,  0.0094,  0.0175],\n        ...,\n        [ 0.1017, -0.0425, -0.0987,  ..., -0.0359,  0.0625, -0.0482],\n        [ 0.0148,  0.0296, -0.1054,  ..., -0.0814,  0.0723, -0.0120],\n        [ 0.0500,  0.0574,  0.0312,  ..., -0.1243, -0.0971,  0.1032]],\n       requires_grad=True)"
                                        },
                                        "_state_dict_hooks":	{},
                                        "in_features":	64,
                                        "out_features":	64,
                                        "training":	true
                                    }
                                },
                                "3":	{
                                    "Tanh()":	{
                                        "_backward_hooks":	{},
                                        "_buffers":	{},
                                        "_forward_hooks":	{},
                                        "_forward_pre_hooks":	{},
                                        "_load_state_dict_pre_hooks":	{},
                                        "_modules":	{},
                                        "_non_persistent_buffers_set":	"set()",
                                        "_parameters":	{},
                                        "_state_dict_hooks":	{},
                                        "training":	true
                                    }
                                },
                                "4":	{
                                    "Linear(in_features=64, out_features=2, bias=True)":	{
                                        "_backward_hooks":	{},
                                        "_buffers":	{},
                                        "_forward_hooks":	{},
                                        "_forward_pre_hooks":	{},
                                        "_load_state_dict_pre_hooks":	{},
                                        "_modules":	{},
                                        "_non_persistent_buffers_set":	"set()",
                                        "_parameters":	{
                                            "bias":	"Parameter containing:\ntensor([-0., 0.], requires_grad=True)",
                                            "weight":	"Parameter containing:\ntensor([[-9.0593e-03, -5.7714e-03, -1.1629e-02,  7.1402e-03, -8.9560e-04,\n          5.6841e-03,  8.2993e-03,  3.9848e-03,  6.0741e-03, -1.0141e-02,\n         -8.6981e-03, -1.3870e-03,  3.7917e-04, -9.0901e-03,  1.1773e-02,\n         -1.1293e-02, -7.0528e-03, -4.9504e-03, -5.6641e-03,  1.1073e-02,\n         -3.9404e-03,  1.7752e-03,  2.0752e-04,  1.1244e-02,  4.4073e-03,\n          8.4379e-03,  4.6590e-03,  1.0776e-02, -8.5071e-03,  9.6056e-03,\n         -5.7509e-03,  3.0118e-04,  9.7896e-03, -6.3426e-03, -3.7848e-03,\n         -1.2486e-02, -1.7134e-03,  1.1765e-02, -6.2197e-06,  1.1862e-02,\n         -1.0749e-02,  3.9092e-03,  6.6097e-03,  7.3458e-03, -1.0869e-02,\n         -4.9005e-03, -3.7488e-03, -1.2336e-02,  1.0913e-02, -8.2800e-03,\n          1.0733e-02,  1.1024e-02, -7.5854e-03, -2.0036e-04,  6.6050e-03,\n         -1.5678e-03, -7.9474e-03, -3.8612e-03, -8.0464e-03,  1.1005e-02,\n         -9.0046e-03,  5.6642e-03, -2.9189e-03, -9.8957e-03],\n        [-1.2393e-02,  1.1136e-02,  9.3192e-03,  4.5420e-03,  7.3658e-03,\n         -4.9418e-03, -1.1346e-02, -1.1669e-02,  6.8598e-03,  3.1753e-03,\n         -9.6692e-03,  1.0578e-02,  8.8273e-03,  3.4194e-03,  7.7702e-04,\n          9.8738e-03, -1.2021e-02,  5.3850e-03,  1.0483e-02, -2.2270e-04,\n          2.6160e-03,  5.8538e-03, -1.0767e-02,  1.0351e-03,  4.0430e-03,\n          1.4126e-03, -9.4084e-05, -9.2370e-03, -8.4414e-03, -7.2095e-03,\n         -1.1478e-02, -4.4379e-03, -1.1372e-02,  9.1958e-03, -8.4558e-03,\n          1.1123e-02,  2.6800e-03, -1.5648e-03, -1.2272e-02,  2.2025e-03,\n         -6.9456e-03, -2.8344e-03, -7.4369e-03, -1.0147e-02, -7.9106e-03,\n          3.0653e-03,  4.3344e-03, -8.8033e-03,  2.9975e-04, -7.5011e-03,\n          7.2806e-03, -4.2036e-03,  4.3761e-03, -8.6310e-03, -7.2043e-03,\n          3.0224e-03, -1.0924e-02, -7.8474e-04, -3.3958e-03,  7.0356e-05,\n         -2.6126e-03,  7.1260e-04,  1.2410e-02, -2.8833e-03]],\n       requires_grad=True)"
                                        },
                                        "_state_dict_hooks":	{},
                                        "in_features":	64,
                                        "out_features":	2,
                                        "training":	true
                                    }
                                },
                                "5":	{
                                    "DiagGaussianLayer()":	{
                                        "_backward_hooks":	{},
                                        "_buffers":	{},
                                        "_forward_hooks":	{},
                                        "_forward_pre_hooks":	{},
                                        "_load_state_dict_pre_hooks":	{},
                                        "_modules":	{},
                                        "_non_persistent_buffers_set":	"set()",
                                        "_parameters":	{
                                            "log_std":	"Parameter containing:\ntensor([0., 0.], requires_grad=True)"
                                        },
                                        "_state_dict_hooks":	{},
                                        "training":	true
                                    }
                                }
                            },
                            "_non_persistent_buffers_set":	"set()",
                            "_parameters":	{},
                            "_state_dict_hooks":	{},
                            "training":	true
                        }
                    }
                }
            },
            "target_kl":	0.01,
            "train_c_iters":	5,
            "train_v_iters":	5,
            "val_l2_reg":	0.001,
            "value_fun":	{
                "Sequential(\n  (0): Linear(in_features=61, out_features=64, bias=True)\n  (1): Tanh()\n  (2): Linear(in_features=64, out_features=64, bias=True)\n  (3): Tanh()\n  (4): Linear(in_features=64, out_features=1, bias=True)\n)":	{
                    "_backward_hooks":	{},
                    "_buffers":	{},
                    "_forward_hooks":	{},
                    "_forward_pre_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "0":	{
                            "Linear(in_features=61, out_features=64, bias=True)":	{
                                "_backward_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_pre_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 0.0035,  0.0500,  0.0706, -0.0529,  0.1218,  0.0459, -0.0373, -0.0950,\n         0.0988, -0.0195,  0.0277,  0.1239, -0.0008,  0.0019, -0.0888, -0.0033,\n        -0.1127, -0.0657,  0.0198,  0.0590,  0.1124, -0.0632, -0.1260,  0.0990,\n        -0.0372, -0.0708,  0.0593, -0.0030,  0.0294, -0.0878,  0.1004, -0.0053,\n         0.0926, -0.0861, -0.0301, -0.1076, -0.0942,  0.0690,  0.1243,  0.0649,\n        -0.0463, -0.1217, -0.0192,  0.0645, -0.0449, -0.0754,  0.0908,  0.1040,\n         0.0767,  0.0820,  0.1097, -0.0023,  0.0168,  0.0917, -0.0116, -0.0454,\n        -0.1028,  0.0910,  0.0807,  0.1191, -0.0290, -0.1244, -0.1226, -0.0600],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.0762,  0.1207, -0.0643,  ..., -0.0880, -0.1213,  0.0474],\n        [-0.1173, -0.0970,  0.0585,  ...,  0.0114,  0.0102,  0.0373],\n        [-0.1155,  0.0434,  0.1227,  ..., -0.0414,  0.0097, -0.0026],\n        ...,\n        [-0.0237, -0.1219,  0.0018,  ...,  0.0855,  0.0563,  0.0756],\n        [ 0.0844, -0.0713, -0.0932,  ...,  0.1022,  0.0678, -0.0426],\n        [ 0.1132, -0.0102, -0.0752,  ...,  0.0831, -0.1184,  0.0828]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "in_features":	"61",
                                "out_features":	64,
                                "training":	true
                            }
                        },
                        "1":	{
                            "Tanh()":	{
                                "_backward_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_pre_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "training":	true
                            }
                        },
                        "2":	{
                            "Linear(in_features=64, out_features=64, bias=True)":	{
                                "_backward_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_pre_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.1076, -0.1206,  0.0129, -0.0004, -0.1126, -0.0160,  0.0083, -0.1033,\n        -0.1161, -0.0694,  0.0378,  0.0579, -0.0221,  0.0996, -0.0467,  0.0580,\n        -0.0666, -0.0853, -0.0767, -0.0670,  0.0964,  0.0407,  0.0065,  0.0110,\n        -0.1039, -0.0834, -0.0385,  0.0759,  0.1034,  0.0806, -0.0557, -0.0474,\n         0.0398, -0.0007,  0.0203, -0.0596,  0.0071, -0.0982,  0.0316,  0.1123,\n         0.0587, -0.0208,  0.0307,  0.0374,  0.0390,  0.0387,  0.0466,  0.0195,\n        -0.0809, -0.0911, -0.0358,  0.0877,  0.1080,  0.0334, -0.1098,  0.0481,\n         0.0093,  0.0312,  0.0887, -0.1017,  0.0736, -0.0848,  0.0153,  0.0498],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.0495, -0.0735, -0.0627,  ..., -0.0267,  0.0796, -0.0521],\n        [ 0.0741, -0.0557, -0.0072,  ...,  0.0254, -0.0688, -0.0541],\n        [ 0.0438,  0.0174,  0.0220,  ...,  0.0135, -0.0651,  0.1022],\n        ...,\n        [-0.0671,  0.0200, -0.0692,  ..., -0.0012, -0.1151, -0.0472],\n        [-0.0670, -0.0400, -0.0084,  ..., -0.0901,  0.0818, -0.0911],\n        [-0.0438,  0.0083, -0.0109,  ..., -0.0191, -0.1135, -0.0721]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "in_features":	64,
                                "out_features":	64,
                                "training":	true
                            }
                        },
                        "3":	{
                            "Tanh()":	{
                                "_backward_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_pre_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "training":	true
                            }
                        },
                        "4":	{
                            "Linear(in_features=64, out_features=1, bias=True)":	{
                                "_backward_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_pre_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.0311], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 0.0803, -0.0920, -0.1097,  0.0158, -0.0882,  0.0359,  0.0464, -0.0273,\n         -0.0384, -0.0962,  0.0666, -0.0136, -0.0263,  0.0588, -0.0204,  0.0378,\n         -0.0425, -0.0045,  0.0155,  0.0034,  0.1113,  0.0487, -0.0506, -0.0729,\n          0.0586,  0.0597,  0.0270,  0.0497, -0.0455,  0.0020, -0.1061, -0.0516,\n          0.0022,  0.1040,  0.0706,  0.0746, -0.0593, -0.1223,  0.0866,  0.0258,\n         -0.1212, -0.0450, -0.1136, -0.0532, -0.0023,  0.0506, -0.1164, -0.0148,\n          0.0343,  0.0039, -0.0250,  0.0438,  0.1119,  0.0636, -0.0652,  0.0763,\n          0.0068, -0.0902,  0.0302,  0.1149,  0.0961, -0.0335,  0.0776,  0.0491]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "in_features":	64,
                                "out_features":	1,
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "training":	true
                }
            },
            "value_fun_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    eps: 1e-08\n    lr: 0.01\n    weight_decay: 0\n)":	{
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "eps":	1e-08,
                        "lr":	0.01,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "eps":	1e-08,
                            "lr":	0.01,
                            "params":	[
                                "Parameter containing:\ntensor([[-0.0762,  0.1207, -0.0643,  ..., -0.0880, -0.1213,  0.0474],\n        [-0.1173, -0.0970,  0.0585,  ...,  0.0114,  0.0102,  0.0373],\n        [-0.1155,  0.0434,  0.1227,  ..., -0.0414,  0.0097, -0.0026],\n        ...,\n        [-0.0237, -0.1219,  0.0018,  ...,  0.0855,  0.0563,  0.0756],\n        [ 0.0844, -0.0713, -0.0932,  ...,  0.1022,  0.0678, -0.0426],\n        [ 0.1132, -0.0102, -0.0752,  ...,  0.0831, -0.1184,  0.0828]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.0035,  0.0500,  0.0706, -0.0529,  0.1218,  0.0459, -0.0373, -0.0950,\n         0.0988, -0.0195,  0.0277,  0.1239, -0.0008,  0.0019, -0.0888, -0.0033,\n        -0.1127, -0.0657,  0.0198,  0.0590,  0.1124, -0.0632, -0.1260,  0.0990,\n        -0.0372, -0.0708,  0.0593, -0.0030,  0.0294, -0.0878,  0.1004, -0.0053,\n         0.0926, -0.0861, -0.0301, -0.1076, -0.0942,  0.0690,  0.1243,  0.0649,\n        -0.0463, -0.1217, -0.0192,  0.0645, -0.0449, -0.0754,  0.0908,  0.1040,\n         0.0767,  0.0820,  0.1097, -0.0023,  0.0168,  0.0917, -0.0116, -0.0454,\n        -0.1028,  0.0910,  0.0807,  0.1191, -0.0290, -0.1244, -0.1226, -0.0600],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.0495, -0.0735, -0.0627,  ..., -0.0267,  0.0796, -0.0521],\n        [ 0.0741, -0.0557, -0.0072,  ...,  0.0254, -0.0688, -0.0541],\n        [ 0.0438,  0.0174,  0.0220,  ...,  0.0135, -0.0651,  0.1022],\n        ...,\n        [-0.0671,  0.0200, -0.0692,  ..., -0.0012, -0.1151, -0.0472],\n        [-0.0670, -0.0400, -0.0084,  ..., -0.0901,  0.0818, -0.0911],\n        [-0.0438,  0.0083, -0.0109,  ..., -0.0191, -0.1135, -0.0721]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.1076, -0.1206,  0.0129, -0.0004, -0.1126, -0.0160,  0.0083, -0.1033,\n        -0.1161, -0.0694,  0.0378,  0.0579, -0.0221,  0.0996, -0.0467,  0.0580,\n        -0.0666, -0.0853, -0.0767, -0.0670,  0.0964,  0.0407,  0.0065,  0.0110,\n        -0.1039, -0.0834, -0.0385,  0.0759,  0.1034,  0.0806, -0.0557, -0.0474,\n         0.0398, -0.0007,  0.0203, -0.0596,  0.0071, -0.0982,  0.0316,  0.1123,\n         0.0587, -0.0208,  0.0307,  0.0374,  0.0390,  0.0387,  0.0466,  0.0195,\n        -0.0809, -0.0911, -0.0358,  0.0877,  0.1080,  0.0334, -0.1098,  0.0481,\n         0.0093,  0.0312,  0.0887, -0.1017,  0.0736, -0.0848,  0.0153,  0.0498],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.0803, -0.0920, -0.1097,  0.0158, -0.0882,  0.0359,  0.0464, -0.0273,\n         -0.0384, -0.0962,  0.0666, -0.0136, -0.0263,  0.0588, -0.0204,  0.0378,\n         -0.0425, -0.0045,  0.0155,  0.0034,  0.1113,  0.0487, -0.0506, -0.0729,\n          0.0586,  0.0597,  0.0270,  0.0497, -0.0455,  0.0020, -0.1061, -0.0516,\n          0.0022,  0.1040,  0.0706,  0.0746, -0.0593, -0.1223,  0.0866,  0.0258,\n         -0.1212, -0.0450, -0.1136, -0.0532, -0.0023,  0.0506, -0.1164, -0.0148,\n          0.0343,  0.0039, -0.0250,  0.0438,  0.1119,  0.0636, -0.0652,  0.0763,\n          0.0068, -0.0902,  0.0302,  0.1149,  0.0961, -0.0335,  0.0776,  0.0491]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0311], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "vf_lr":	0.01
        }
    }
}